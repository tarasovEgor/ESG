{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "import torch\n",
    "from enum import Enum\n",
    "import ast\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizerFast, BertModel, BertConfig, get_scheduler\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentencesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        metalurgi,\n",
    "        prokuror,\n",
    "        prokuror_col,\n",
    "        data_size=None,\n",
    "        close_sent_dist=1,\n",
    "        far_sent_dist=10,\n",
    "    ):\n",
    "        self.metalurgi = metalurgi\n",
    "        self.prokuror = prokuror\n",
    "        self.prokuror_col = prokuror_col\n",
    "        self.exsist_inn = self.prokuror.loc[\n",
    "            self.prokuror[\"INN\"].isin(self.metalurgi[\"INN\"]), \"INN\"\n",
    "        ].unique()\n",
    "        self.data_size = (\n",
    "            data_size\n",
    "            if data_size is not None\n",
    "            else min(self.metalurgi.shape[0], self.prokuror.shape[0])\n",
    "        )\n",
    "        self.close_sent_dist = close_sent_dist\n",
    "        self.far_sent_dist = far_sent_dist\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        first, second = 0, 0\n",
    "        label = idx % 2\n",
    "\n",
    "        if idx % 2:\n",
    "            first_sentence, second_sentence = self.get_positive_example()\n",
    "        else:\n",
    "            first_sentence, second_sentence = self.get_negative_example()\n",
    "\n",
    "        examples = {\n",
    "            \"sentence1\": first_sentence,\n",
    "            \"sentence2\": second_sentence,\n",
    "            \"label\": label,\n",
    "        }\n",
    "\n",
    "        return examples\n",
    "\n",
    "    def get_positive_example(self):\n",
    "        second_sentence = None\n",
    "        while second_sentence is None or pd.isnull(second_sentence):\n",
    "            inn = np.random.choice(self.exsist_inn)\n",
    "            first_id = np.random.choice(\n",
    "                self.metalurgi[self.metalurgi[\"INN\"] == inn].index\n",
    "            )\n",
    "            first_sentence = self.metalurgi.at[first_id, \"line\"]\n",
    "            second_id = np.random.choice(\n",
    "                self.prokuror[self.prokuror[\"INN\"] == inn].index\n",
    "            )\n",
    "            second_sentence = self.prokuror.at[second_id, \"line\"]\n",
    "        return first_sentence, second_sentence\n",
    "\n",
    "    def get_negative_example(self):\n",
    "        second_sentence = None\n",
    "        while second_sentence is None or pd.isnull(second_sentence):\n",
    "            first_id = np.random.choice(self.metalurgi.shape[0])\n",
    "            second_id = np.random.choice(self.prokuror.shape[0])\n",
    "            while (\n",
    "                self.metalurgi.iloc[first_id][\"INN\"]\n",
    "                == self.prokuror.iloc[second_id][\"INN\"]\n",
    "            ):\n",
    "                second_id = np.random.choice(self.prokuror.shape[0])\n",
    "            first_sentence = self.metalurgi.iloc[first_id][\"line\"]\n",
    "            second_sentence = self.prokuror.iloc[second_id][\"line\"]\n",
    "        return first_sentence, second_sentence\n",
    "\n",
    "\n",
    "class TransformText:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, data):\n",
    "        sentences1 = []\n",
    "        sentences2 = []\n",
    "        labels = []\n",
    "        for example in data:\n",
    "            sentences1.append(example[\"sentence1\"])\n",
    "            sentences2.append(example[\"sentence2\"])\n",
    "            labels.append(example[\"label\"])\n",
    "        labels = torch.tensor(labels)\n",
    "        try:\n",
    "            sentences1 = self.transform(sentences1)\n",
    "            sentences2 = self.transform(sentences2)\n",
    "        except TypeError:\n",
    "            print(sentences1, sentences2)\n",
    "            raise TypeError(f\"{sentences1}, {sentences2}\")\n",
    "        return sentences1, sentences2, labels\n",
    "\n",
    "    def transform(self, sentences):\n",
    "        sentences = self.tokenizer(\n",
    "            sentences,\n",
    "            max_length=512,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDistanceMetric(Enum):\n",
    "    EUCLIDEAN = lambda x, y: F.pairwise_distance(x, y, p=2)\n",
    "    MANHATTAN = lambda x, y: F.pairwise_distance(x, y, p=1)\n",
    "    COSINE_DISTANCE = lambda x, y: 1 - F.cosine_similarity(x, y)\n",
    "\n",
    "\n",
    "class Probability(nn.Module):\n",
    "    def __init__(self, distance_metric=SiameseDistanceMetric.EUCLIDEAN):\n",
    "        super(Probability, self).__init__()\n",
    "        self.distance_metric = distance_metric\n",
    "        self.alpha = torch.nn.Parameter(torch.ones(1), requires_grad=False)\n",
    "\n",
    "    def get_config_dict(self):\n",
    "        distance_metric_name = self.distance_metric.__name__\n",
    "        for name, value in vars(SiameseDistanceMetric).items():\n",
    "            if value == self.distance_metric:\n",
    "                distance_metric_name = \"SiameseDistanceMetric.{}\".format(name)\n",
    "                break\n",
    "        return {\"distance_metric\": distance_metric_name, \"alpha\": self.alpha}\n",
    "\n",
    "    def forward(self, sentence1: Tensor, sentence2: Tensor):\n",
    "        distances = self.distance_metric(sentence1, sentence2)\n",
    "        prob = 2 / (1 + torch.exp(distances * (self.alpha**2)))\n",
    "        return prob\n",
    "\n",
    "    def device(self):\n",
    "        return self.alpha.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Loss, self).__init__()\n",
    "\n",
    "    def get_config_dict(self):\n",
    "        return {}\n",
    "\n",
    "    def forward(self, prob: Tensor, labels: Tensor):\n",
    "        losses = labels * torch.log(prob) + (1 - labels) * torch.log(1 - prob)\n",
    "        return -losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbModel(nn.Module):\n",
    "    def __init__(self, bert, custom_bert):\n",
    "        super(ProbModel, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.custom_bert = custom_bert\n",
    "        self.dense = nn.Linear(768, 768)\n",
    "        self.probability = Probability()\n",
    "\n",
    "    def forward(self, sentence1: Tensor, sentence2: Tensor):\n",
    "        a = self.get_embedding(sentence1)\n",
    "        b = self.get_embedding(sentence2, True)\n",
    "\n",
    "        p = self.probability(a, b)\n",
    "\n",
    "        return p\n",
    "\n",
    "    def get_embedding(self, sentence, custom_model=False):\n",
    "        device = self.probability.device()\n",
    "        anchor_ids = sentence[\"input_ids\"]  # .to(device)\n",
    "        anchor_mask = sentence[\"attention_mask\"]  # .to(device)\n",
    "        if custom_model:\n",
    "            a = self.custom_bert(anchor_ids, attention_mask=anchor_mask)[0][:, 0]\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                a = self.bert(anchor_ids, attention_mask=anchor_mask)[0][:, 0]\n",
    "        a = self.dense(a)\n",
    "\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_layers(model, start, end):\n",
    "    for p in model.base_model.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    for layer in range(start, end):\n",
    "        for p in model.base_model.encoder.layer[layer].parameters():\n",
    "            p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3022028, 5), (4517712, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalurg_df = pd.read_csv(\"parsed_metalurgs_v3_only_prokuror.csv\", index_col=0)\n",
    "prokuror_df = pd.read_csv(\"prokuror_results.csv\", index_col=0, engine=\"python\")\n",
    "metalurg_df = metalurg_df.rename(columns={\"Код налогоплательщика\": \"INN\"})\n",
    "\n",
    "prokuror_df.shape, metalurg_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3022028 entries, 0 to 3019345\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   path      object \n",
      " 1   INN       float64\n",
      " 2   column    object \n",
      " 3   line      object \n",
      " 4   sent_num  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 138.3+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4517712 entries, 58748 to 20555692\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   path        object \n",
      " 1   sent_num    int64  \n",
      " 2   line        object \n",
      " 3   INN         int64  \n",
      " 4   p1_topic 1  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 206.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prokuror_df.info(), metalurg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>INN</th>\n",
       "      <th>column</th>\n",
       "      <th>line</th>\n",
       "      <th>sent_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>result_1</td>\n",
       "      <td>7.325142e+09</td>\n",
       "      <td>OKVEDS</td>\n",
       "      <td>Деятельность ресторанов и услуги по доставке п...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>result_1</td>\n",
       "      <td>7.325142e+09</td>\n",
       "      <td>REASON</td>\n",
       "      <td>(ФЗ 248) Наличие у контрольного (надзорного) о...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>result_1</td>\n",
       "      <td>7.325143e+09</td>\n",
       "      <td>OKVEDS</td>\n",
       "      <td>Деятельность ресторанов и услуги по доставке п...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>result_1</td>\n",
       "      <td>7.325143e+09</td>\n",
       "      <td>REASON</td>\n",
       "      <td>(ФЗ 248) Наличие у контрольного (надзорного) о...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>result_1</td>\n",
       "      <td>5.610097e+09</td>\n",
       "      <td>OKVEDS</td>\n",
       "      <td>Деятельность автомобильного грузового транспор...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       path           INN  column  \\\n",
       "0  result_1  7.325142e+09  OKVEDS   \n",
       "1  result_1  7.325142e+09  REASON   \n",
       "2  result_1  7.325143e+09  OKVEDS   \n",
       "3  result_1  7.325143e+09  REASON   \n",
       "4  result_1  5.610097e+09  OKVEDS   \n",
       "\n",
       "                                                line  sent_num  \n",
       "0  Деятельность ресторанов и услуги по доставке п...       0.0  \n",
       "1  (ФЗ 248) Наличие у контрольного (надзорного) о...       1.0  \n",
       "2  Деятельность ресторанов и услуги по доставке п...       0.0  \n",
       "3  (ФЗ 248) Наличие у контрольного (надзорного) о...       1.0  \n",
       "4  Деятельность автомобильного грузового транспор...       0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prokuror_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>line</th>\n",
       "      <th>INN</th>\n",
       "      <th>p1_topic 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20555688</th>\n",
       "      <td>Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...</td>\n",
       "      <td>183</td>\n",
       "      <td>Профили из нержавеющей стали</td>\n",
       "      <td>6311074905</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555689</th>\n",
       "      <td>Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...</td>\n",
       "      <td>186</td>\n",
       "      <td>Профили для ступеней входной группы</td>\n",
       "      <td>6311074905</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555690</th>\n",
       "      <td>Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...</td>\n",
       "      <td>197</td>\n",
       "      <td>Данный носит исключительно информационный хара...</td>\n",
       "      <td>6311074905</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555691</th>\n",
       "      <td>Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...</td>\n",
       "      <td>258</td>\n",
       "      <td>Отправьте нам ваше резюме</td>\n",
       "      <td>6311074905</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20555692</th>\n",
       "      <td>Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...</td>\n",
       "      <td>261</td>\n",
       "      <td>Нажимая на кнопку вы подтверждаете что согласн...</td>\n",
       "      <td>6311074905</td>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       path  sent_num  \\\n",
       "20555688  Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...       183   \n",
       "20555689  Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...       186   \n",
       "20555690  Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...       197   \n",
       "20555691  Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...       258   \n",
       "20555692  Sber_parser/3801-4001/data/ЛУКА, ООО_105631100...       261   \n",
       "\n",
       "                                                       line         INN  \\\n",
       "20555688                       Профили из нержавеющей стали  6311074905   \n",
       "20555689                Профили для ступеней входной группы  6311074905   \n",
       "20555690  Данный носит исключительно информационный хара...  6311074905   \n",
       "20555691                          Отправьте нам ваше резюме  6311074905   \n",
       "20555692  Нажимая на кнопку вы подтверждаете что согласн...  6311074905   \n",
       "\n",
       "          p1_topic 1  \n",
       "20555688    0.002909  \n",
       "20555689    0.002909  \n",
       "20555690    0.002909  \n",
       "20555691    0.002909  \n",
       "20555692    0.002909  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metalurg_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model_name = \"DeepPavlov/rubert-base-cased\"\n",
    "config = BertConfig.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "orig_model = BertModel.from_pretrained(model_name, config=config)\n",
    "custom_model = BertModel.from_pretrained(\n",
    "    \"/home/rsolomatin/metalurgi/site-prokuror/Models/transformers/DeepPavlov/rubert-base-cased-sentence\",\n",
    "    config=config,\n",
    ")\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_layers(custom_model, 11, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train = SentencesDataset(\n",
    "    metalurg_df, prokuror_df, [\"REASON\", \"WARNING_INFO\"], data_size=10000\n",
    ")\n",
    "batch_transformer = TransformText(tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, collate_fn=batch_transformer)\n",
    "\n",
    "total_steps = int(len(train_loader) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loss()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = ProbModel(orig_model, custom_model).to(device)\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=0.00001)\n",
    "loss_func = Loss()\n",
    "loss_func.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "\n",
    "def fit(\n",
    "    model,\n",
    "    loss_func,\n",
    "    train_loader,\n",
    "    optim,\n",
    "    device,\n",
    "    epochs=3,\n",
    "    model_save_path=\"model\",\n",
    "    disable_tqdm=False,\n",
    "):\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    epoch = 0\n",
    "\n",
    "    # Loading the latest model\n",
    "    best_filename = \"\"\n",
    "    for filename in os.listdir(model_save_path):\n",
    "        if not filename.endswith(\".pth\"):\n",
    "            continue\n",
    "\n",
    "        if len(filename) < len(best_filename):\n",
    "            continue\n",
    "        if len(filename) == len(best_filename) and filename < best_filename:\n",
    "            continue\n",
    "        best_filename = filename\n",
    "    if best_filename != \"\":\n",
    "        saved_state = torch.load(model_save_path + \"/\" + best_filename)\n",
    "        epoch = saved_state[\"epoch\"]\n",
    "        model.load_state_dict(saved_state[\"model\"])\n",
    "\n",
    "    # Starting over the epochs\n",
    "    result = []\n",
    "    while epoch < epochs:\n",
    "        epoch += 1\n",
    "        result = []\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for i, batch in tqdm(\n",
    "            enumerate(train_loader),\n",
    "            desc=f\"Epoch {epoch}/{epochs} train\",\n",
    "            total=len(train_loader),\n",
    "        ):\n",
    "            sentence1, sentence2, labels = batch\n",
    "\n",
    "            probability = model(sentence1, sentence2)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            loss = loss_func(probability, labels)\n",
    "\n",
    "            batch_result = pd.DataFrame(\n",
    "                {\n",
    "                    \"Type\": \"Train\",\n",
    "                    \"Epoch\": epoch,\n",
    "                    \"Batch\": i,\n",
    "                    \"Probs\": [p.item() for p in probability],\n",
    "                    \"Labels\": labels.cpu().numpy(),\n",
    "                    \"Losses\": loss.item(),\n",
    "                }\n",
    "            )\n",
    "            result.append(batch_result)\n",
    "\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            optim.zero_grad()\n",
    "\n",
    "        res = pd.DataFrame().append(result)\n",
    "        result = [res]\n",
    "        sel = (res.Type == \"Train\") & (res.Epoch == epoch)\n",
    "\n",
    "        print(f\"=====TRAIN(Epoch {epoch})=====\")\n",
    "        accuracy_train, qqs_train, label_mean_train = analyse_quality(res[sel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(model, loss_func, train_loader, optim, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
